{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week 08",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habeebperwad/mlesa/blob/master/Assignment%2008.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Usd9MUv1qZp-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###1. While training a vanilla RNN, the ML engineer finds that the weights keep growing with each epoch. Which of the following could be the possible reasons and solutions:\n",
        "- **A**. High learning rate. Try lowering learning rate.\n",
        "- **B**. Not enough data. Get more training data.\n",
        "- **C**. Bad architecture. Use LSTM\n",
        "- **D RIGHT**. Exploding gradients. Try clipping gradient.\n",
        "---\n",
        "-  Accepted answer is A and D. \n",
        "\n",
        "I think the 'learning rate' option will be right only if 'the **magnitude of** weights keep growing'. \n",
        "Because high learning rate causes for instabiity. Means 'the **magnitude of** weights keep growing' but sign will keep on changing to negative and positive.\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "9ZFJq6fAq5PR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Which of the following statements are true\n",
        "- **A**.The forward pass of Vanilla RNNs is cheaper than that of GRUs and LSTMs\n",
        "- **B**. Amongst GRUs, LSTMs and Vanilla RNNs, only LSTMs have a separate memory cell\n",
        "- **C**. Usually, LSTMs can compute deeper sequences (without vanishing gradients) compared to GRUs\n",
        "- **D RIGHT**. All of the above"
      ]
    },
    {
      "metadata": {
        "id": "RV2E0_cCrYIm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. What common property of  AlexNet, LSTMs and ResNet helps in training?\n",
        "- **A**. The number of their layers.\n",
        "- **B**. The number of parameters\n",
        "- **C RIGHT**. They have multiple pathways for gradient backflow which helps in backprop\n",
        "- **D**. All of the above\n",
        "\n",
        "**LOOK LIKE THE QUESTION IS WRONG. AlexNet is odd here.**"
      ]
    },
    {
      "metadata": {
        "id": "QUcjw9VsaZpS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A company is trying to automate case reports for MRI scans. The scans are videos of a beating heart at a particular cross section (slice). The automatic report is supposed to give a diagnosis amongst 5 different conditions (one of which is a “normal heart”). The videos are of 30 frames each. Each frame is a 227x227 grayscale image. Answer the following\n",
        "\n",
        "###4. Which is the most appropriate classification for the type of RNN to be used for this problem?\n",
        "-  **A**. One to One\n",
        "-  **B**.  One to Many\n",
        "-  **C RIGHT**.  Many to One\n",
        "-  **D**.  Many to Many"
      ]
    },
    {
      "metadata": {
        "id": "iste9dsGuKmC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. If we are to use the full, unprocessed video as the input to the RNN, which of the following are true?\n",
        "- **A RIGHT**. The unrolled RNN will have a depth of 30 in time.\n",
        "- **B RIGHT**. There are 30 sequential inputs to the RNN each of size 227x227\n",
        "- **C**. There is only 1 non-sequential input to the RNN of size 227x227x30\n",
        "- **D**. The RNN can be a deep RNN with 30 CNN like units\n",
        "\n",
        "-----\n",
        "Accepted Answers:\n",
        "- The unrolled RNN will have a depth of 30 in time.\n",
        "- There are 30 sequential inputs to the RNN each of size 227x227\n",
        "- The RNN can be a deep RNN with 30 CNN like units\n",
        "\n",
        "The input is fixed here.  So We can use CNN here. That means 'deep RNN' will work. \n",
        "Technically that option is correct. But looks like the option is odd.  \n",
        "\n",
        "-----\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "KQ1tGneFuX2q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The ML engineer in the company decides that using the full, unprocessed video is too expensive for an RNN. So, she decides to encode the image by using a CNN architecture similar to Alexnet. The final, fully connected layer in her architecture has size 50. She uses this embedding (final layer) as the input to the RNN for each frame. She also uses a single hidden layer with 100 neurons. Answer the following questions.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "```\n",
        "I assume the input size is (50,1)\n",
        "size of hidden layer is (100, 1) \n",
        "```\n",
        "\n",
        "\n",
        "We know the equations:\n",
        "\n",
        "- h<sub>t</sub> = g( W<sub>hh</sub> * h<sub>t-1</sub> +  W<sub>xh</sub> * x<sub>t</sub> + b<sub>h</sub>)\n",
        "- y<sub>t</sub> = g<sup>\\*</sup>(W<sub>yh</sub> * h<sub>t</sub> ) \n",
        "\n",
        "We know the following matrix sizes:\n",
        "- h<sub>t</sub> and  h<sub>t-1</sub> is (100, 1)\n",
        "- x<sub>t</sub>is (50, 1)\n",
        "\n",
        "The matrix sizes in first equation: (100, 1) = (m<sub>hh</sub> , n<sub>hh</sub>) * (100, 1) + (m<sub>xh</sub> , n<sub>xh</sub>) * (50, 1) + (m<sub>bh</sub> , n<sub>bh</sub>)\n",
        "\n",
        "So W<sub>hh</sub> is (100, 100),  W<sub>xh</sub> is (100, 50) and  b<sub>h</sub> is (100,1)\n",
        "\n",
        "The matrix sizes in Second equation: (100, 1) = (m<sub>yh</sub> , n<sub>yh</sub>) * (100, 1)\n",
        "\n",
        "So W<sub>yh</sub> is (<sub>no data to identify row size</sub> , 100) \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Z6s3EKMDdkS3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 6. What is the size of the matrix  W<sub>hh</sub>?\n",
        "- **A**. 5000x5000\n",
        "- **B**.  50x50\n",
        "- **C RIGHT**.  100x100\n",
        "- **D**.  30x30\n"
      ]
    },
    {
      "metadata": {
        "id": "urVjrRiTdmhE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 7. What is the size of the matrix W<sub>xh</sub>?\n",
        "- **A**. 50x100\n",
        "- **B RIGHT**. 100x50\n",
        "- **C**. 100x100\n",
        "- **D**. 50x50"
      ]
    },
    {
      "metadata": {
        "id": "DwtbpgRPdn0x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 8. What is the size of the bias matrix for the recurrent unit?\n",
        "- **A**. 50x1\n",
        "- **B RIGHT**. 100x1\n",
        "- **C**. 30x1\n",
        "- **D**. 5000x1"
      ]
    },
    {
      "metadata": {
        "id": "RbJq7Rrden2P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###9. What is the size of the matrix W<sub>yh</sub> if we are going to use softmax to classify? Ignore the bias unit here.\n",
        "\n",
        "- **A**. 500x1\n",
        "- **B RIGHT**. 5x100\n",
        "- **C**. 100x5\n",
        "- **D**. 5x5"
      ]
    },
    {
      "metadata": {
        "id": "vCxvXocEe0Jj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 10. What is the total number of parameters that we would have to train in case the RNN architecture used was LSTM. Ignore all bias units as well as the output parameters\n",
        "\n",
        " - **A**. 15000\n",
        " - **B**. 15100\n",
        " - **C**. 45000\n",
        " - **D RIGHT**. 60000"
      ]
    },
    {
      "metadata": {
        "id": "3PoIFYEVgqLV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "LSTM have eight paramers; four **W** and four **U** ( W<sub>xh</sub> is the notation used above for U )\n",
        "\n",
        "Size of W is (100,100) and U is (100, 50)\n",
        "\n",
        "So Total 4x100x100 + 4x100x50 = 60000"
      ]
    }
  ]
}