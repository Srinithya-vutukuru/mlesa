{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week04",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habeebperwad/mlesa/blob/master/Assignment%2004.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hFCdje6iKUTp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. ![alt text](https://onlinecourses.nptel.ac.in/noc19_cs14/assets/img/A4Q1.1.PNG?seed=20316&url=assets/img/A4Q1.1.PNG) \n",
        "\n",
        "~~Answer: **Option D**. None~~\n",
        " \n",
        " - ~~Look like the Option A is answer. That equation uses only one record for updating parameters (i.e. wj). That happens only in *Stochastic gradient descent*. The question doesn't mention *Stochastic*. So I believe we should consider *batch gradient descent* which uses all records. Option A don't consider all the records to update.~~\n",
        " \n",
        " - Got [more details](https://groups.google.com/a/nptel.iitm.ac.in/d/msg/noc19-cs14-discuss/d8ATciQ_ZM0/i2Fp6blaBQAJ) from Balaji Sir: \"**Assume just a single data point which is equivalent to having no summation sign. Alternatively, you can assume this is Stochastic Gradient Descent with a single data point.**\"\n",
        "\n",
        "- The option A look like answer. But there is a negtive sign missing. \n",
        "\n",
        "-----------------\n",
        "- Accepted answer is **Option A**\n",
        "- You may be thinking how it is possible. Do your karma very well and hope the God of luck will turn favour to you!!\n",
        "------------------------\n",
        "\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "DOVr_BnvKWEm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. ![alt text](https://onlinecourses.nptel.ac.in/noc19_cs14/assets/img/A4Q2.1.PNG?seed=16649&url=assets/img/A4Q2.1.PNG)\n",
        "![alt text](https://onlinecourses.nptel.ac.in/noc19_cs14/assets/img/A4Q2.2.PNG?seed=12175&url=assets/img/A4Q2.2.PNG)\n",
        "\n",
        "----------------\n",
        "\n",
        "I believe the question is incomplete. didn't give the range of j of w. Or didn't give summation sigma for j.  \n",
        "\n",
        "Answer: **Option A**. I understood the psychology of the team who evaluate this assignment. I choose this option based on my intuation of what they may choose as answer; not based on facts or knowledge. Sorry, I cannot express my intution in words!\n"
      ]
    },
    {
      "metadata": {
        "id": "27M9Hzb66oji",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3 Which of the following statements are True? Check all that apply:\n",
        "- **A.  RIGHT. If a learning algorithm is suffering from high bias, only adding more training examples may not improve the test error significantly.**\n",
        "  - The reason of high bias is that the learning algorithm is not flexible/complex to capture the  structure of the actual hypothesis. More data can help only if the learning algorithm have enough flexibility/complexity.  \n",
        " \n",
        "- **B. RIGHT: A model with more parameters is more prone to overfitting and typically has a higher variance.**\n",
        "   - There is a famous saying *\"With four parameters I can fit an elephant, and with five I can make him wiggle his trunk.\"\"* It means with more parameters you can fit any data set very well. But that may be overfit!!\n",
        "   - More parameters will make the model learn noise too from the training data (It is called overfitting.) Such model performs well in trainig data, but performs poorly in test data (it is called high variance).   \n",
        "  \n",
        "  ----\n",
        " \n",
        "- **C. RIGHT: When debugging learning algorithms, it is useful to plot a learning curve to understand if there is a high bias or high variance problem.**\n",
        " - Learning curve for training data and test data are used for ploting.\n",
        "   - **High Variance**: Training error is very low and test error is very high\n",
        "   - **High Bias**: Training error is very high\n",
        "  ----\n",
        "\n",
        "- D. WRONG: **Increasing degree of the polynomial in curve fitting will increase the bias in the model.**:\n",
        " - More degree of the polynomial will make the model more complex. Complex model will have low bias.  "
      ]
    },
    {
      "metadata": {
        "id": "H2ZRhsvHFB3m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. The figure below shows the plot of the learning curves of a learning algorithm. It is found that it has an unacceptably high error on the test set. What is the algorithm suffering?\n",
        "![alt text](https://onlinecourses.nptel.ac.in/noc19_cs14/assets/img/A4Q3.PNG?seed=51928&url=assets/img/A4Q3.PNG)\n",
        "\n",
        " - A. WRONG: High Variance: Training error should be low and test error high.\n",
        " - **B. RIGHT. High Bias**: Here training error and test error is almost equal. That means the learning algorithm learnt some actual patterns from training data and didn't learn significant noise from the training data.  The test error is high means the learning algorithm didn't capture the enough patterns of the actual hypothesis.\n",
        " - C. WRONG. High Variance and Low bias: Option A is wrong. \n",
        " - D. WRONG. None: One of the above options is chosen :)"
      ]
    },
    {
      "metadata": {
        "id": "p0egAHzZJVIJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Suppose you have implemented a regularized linear regression model. You observe that on the held out testing set, the model makes unacceptably large errors with its predictions. However, you observe that the model performs well (has a low error) on the training set. Which of the following steps can be incorporated to lower the error on testing dataset. Select all that apply.\n",
        "\n",
        "training error low and test error high means  **high variance**. That means learning alogithm is so complex and learning noise from the training data. Here need to reduce the variance for lower the error on testing dataset.\n",
        "\n",
        "- **A. RIGHT. Try using a smaller set of the features**:\n",
        "  - Some of the feature may not be relevent fetaures. That may cause to learn noises. Remove irrelevant features.\n",
        "\n",
        "- **B**. WRONG. Try decreasing the regularization parameter λ\n",
        "  - Regularizing is the way to control the model become too complex. Reducing the regularization parameter λ means making the model more complex. The model is already enough complex! Adding more complexity will make the situation worse.\n",
        "  \n",
        "- **C. RIGHT: Get more training examples**\n",
        "   - More examples will increase the chance of getting more signal and reduce the capturing the noise. So it will reduce the variance.\n",
        "\n",
        "- **D**. WRONG.  Use fewer training examples\n",
        "   - It will only increase the variance."
      ]
    },
    {
      "metadata": {
        "id": "4FM9P5PtMvaF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. Suppose you have implemented a regularized linear regression model. You observe that on the held out testing set, the model makes unacceptably large errors with its predictions. Furthermore, you observe that the model performs poorly on the training set. Which of the following steps can be incorporated to lower the error on the testing dataset. Select all that apply\n",
        "\n",
        "Both training error and test  error are high. It is the sign of **high bias**. The learning algorithm should be more complex.\n",
        "\n",
        "- **A. RIGHT. Try to obtain an additional set of features**\n",
        "  - More features will make the model more complex.\n",
        "  \n",
        "- **B**. WRONG. Try increasing the regularization parameter λ\n",
        "   - Regularization parameter λ control the complexity of the model. The parameter should be decreased to make the model more complex.  \n",
        "   \n",
        "- **C**. WRONG.Get more training examples\n",
        "   - Adding more won't help much in *high bias* situation.\n",
        " \n",
        "- **D. RIGHT. Try adding polynomial features**\n",
        "   - It is like adding more features.  \n",
        "   \n",
        "   \n",
        "--------------\n",
        " -  Sorry I failed to predict the answers. I may be a bad astrologer!! \n",
        "\n",
        "Accepted Answers:\n",
        "- Try to obtain an additional set of features\n",
        "-  Get more training examples \n",
        "--------"
      ]
    },
    {
      "metadata": {
        "id": "iIAeHHI0O8Vv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 7 Suppose you are training a regularized linear regression model. Check which of the following statements are true? Select all that apply.\n",
        "- A. WRONG. The regularization parameter λ value is chosen so as to give the lowest training set error\n",
        "  - If the objective is to lower the training-error, there is no point of regularization.\n",
        "- **B. RIGHT: The regularization parameter λ value is chosen so as to give the lowest cross validation error**\n",
        "  - [choice-of-regularization-parameter](https://www.datacamp.com/community/tutorials/tutorial-ridge-lasso-elastic-net#choice-of-regularization-parameter)\n",
        "- **C**. WRONG: The regularization parameter λ value is chosen so as to give the lowest test set error\n",
        "   - I assume they didn't mean test-error as valdation-error. We shouldn't tune any hyperparameter according to the performance in the test-error.   \n",
        "- **D. RIGHT. The performance of a learning algorithm on the training set will typically be better than its performance on the test set**\n",
        "  - It is true for linear regression irrespective of regularized or not (So I am bit skeptic about why they gave this option in the context of regularized linear regression.)"
      ]
    },
    {
      "metadata": {
        "id": "T2_HtjSbpfMS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##8. ![alt text](https://onlinecourses.nptel.ac.in/noc19_cs14/assets/img/A4Q8.1.PNG?seed=33500&url=assets/img/A4Q8.1.PNG)\n",
        "![alt text](https://onlinecourses.nptel.ac.in/noc19_cs14/assets/img/A4Q8.2.PNG?seed=50102&url=assets/img/A4Q8.2.PNG)\n",
        "\n",
        "--------\n",
        "Answer: actual  MSE is given below. But look like they have used **MSE/2**\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*3VJyfU1qBqoHwaDJm3KAKA.gif)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "yGJDQvGDqbFJ",
        "colab_type": "code",
        "outputId": "61371218-7af6-464e-89f6-b7e958079872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "x = np.array([1,2, 4, 0])\n",
        "y = np.array([0.5,1, 2, 0])\n",
        "\n",
        "h = lambda w, x : w[0] + w[1]*x # Didn't use anywhere. Take it an example for lambda :)\n",
        "\n",
        "def mse(w):\n",
        "  return 1.0/(2*len(x)) * sum([(yy-w[0]-w[1]*xx)**2 for xx,yy in zip(x,y)])\n",
        "\n",
        "def gradient_mse(w):\n",
        "  return np.array([\n",
        "      1.0/(2*len(x)) * sum([2*(yy-w[0]-w[1]*xx)*-1   for xx,yy in zip(x,y)]), \n",
        "      1.0/(2*len(x)) * sum([2*(yy-w[0]-w[1]*xx)*-xx for xx,yy in zip(x,y)])]) \n",
        "\n",
        "w = np.array([1,1])\n",
        "print(\"ANSWER# 8 :\", mse(w))\n",
        "\n",
        "alpha = 0.1 # learning rate\n",
        "updated_w = w-alpha*gradient_mse(w)\n",
        "print(\"ANSWER# 9 :\", updated_w)\n",
        "\n",
        "print(\"ANSWER# 10 : %.4f\" % mse(updated_w))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANSWER# 8 : 2.03125\n",
            "ANSWER# 9 : [0.8125 0.5625]\n",
            "ANSWER# 10 : 0.4292\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}